{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b283079e",
   "metadata": {},
   "source": [
    "Multilayer Perceptron from scatch using only Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3075a2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 loss  2.3030613579436188 accuracy  0.1292 lr\n",
      "Epoch:  1 loss  2.269999021887757 accuracy  0.1569 lr\n",
      "Epoch:  2 loss  2.2327471339653147 accuracy  0.1809 lr\n",
      "Epoch:  3 loss  2.175935506686134 accuracy  0.2537 lr\n",
      "Epoch:  4 loss  2.107357546919856 accuracy  0.3382 lr\n",
      "Epoch:  5 loss  2.0132164237537733 accuracy  0.4094 lr\n",
      "Epoch:  6 loss  1.885729600706711 accuracy  0.5179 lr\n",
      "Epoch:  7 loss  1.724287963214142 accuracy  0.5838 lr\n",
      "Epoch:  8 loss  1.5300310964582298 accuracy  0.6095 lr\n",
      "Epoch:  9 loss  1.3264636770960865 accuracy  0.6362 lr\n",
      "Epoch:  10 loss  1.1363039838078155 accuracy  0.6846 lr\n",
      "Epoch:  11 loss  0.972959713439082 accuracy  0.7305 lr\n",
      "Epoch:  12 loss  0.855178733510388 accuracy  0.7514 lr\n",
      "Epoch:  13 loss  0.7728648418321366 accuracy  0.7797 lr\n",
      "Epoch:  14 loss  0.7376282638492357 accuracy  0.7506 lr\n",
      "Epoch:  15 loss  0.8824016773898127 accuracy  0.6949 lr\n",
      "Epoch:  16 loss  1.3564448162131728 accuracy  0.6239 lr\n",
      "Epoch:  17 loss  1.2332720264035142 accuracy  0.6452 lr\n",
      "Epoch:  18 loss  1.9263796007825473 accuracy  0.4464 lr\n",
      "Epoch:  19 loss  1.260401764044902 accuracy  0.5894 lr\n",
      "Epoch:  20 loss  1.3127396368064235 accuracy  0.5902 lr\n",
      "Epoch:  21 loss  1.2969150547512747 accuracy  0.5925 lr\n",
      "Epoch:  22 loss  1.1798399608679102 accuracy  0.6206 lr\n",
      "Epoch:  23 loss  0.9658994038944706 accuracy  0.6916 lr\n",
      "Epoch:  24 loss  0.8733958582022892 accuracy  0.7101 lr\n",
      "Epoch:  25 loss  0.7557407292349135 accuracy  0.7609 lr\n",
      "Epoch:  26 loss  0.6821224042086901 accuracy  0.7864 lr\n",
      "Epoch:  27 loss  0.6357745238001197 accuracy  0.8089 lr\n",
      "Epoch:  28 loss  0.5793764057150392 accuracy  0.816 lr\n",
      "Epoch:  29 loss  0.548352980812181 accuracy  0.82 lr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2282134d4f0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the code\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import datasets \n",
    "#portion 1\n",
    "(X_train , y_train) , ( X_test , y_test ) = datasets.mnist.load_data( )\n",
    "n_train = 10000 #number of training data to use\n",
    "X_train = X_train[:n_train,:,:]\n",
    "X_test = X_test[:n_train,:,:]\n",
    "y_train=y_train[:n_train]\n",
    "X_train = X_train.reshape(n_train, 784)/255\n",
    "X_test = X_test.reshape(n_train, 784) / 255\n",
    "\n",
    "\n",
    "n_epoch=30\n",
    "#portion 6\n",
    "class Optimizer_StoGradDesc:\n",
    "\n",
    "    # This is to be used to reset the weights to that gotten after backpropagation\n",
    "    #this implements the decay learning rate regularization\n",
    "    def __init__(self, learning_rate=0.1,decay=0, momentum=0.5):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate=learning_rate\n",
    "        self.decay =decay\n",
    "        self.counter=0\n",
    "        self.momentum=momentum\n",
    "    def pre_update_params(self):\n",
    "        #this adjusts the learning rate using the decay value\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate* (1. / (1. + self.decay * self.counter))\n",
    "    def update_params(self, layer):\n",
    "        \n",
    "        #this implements the momentum regularization\n",
    "        if self.momentum:\n",
    "            if not hasattr(layer,'weight_momentums'):\n",
    "                layer.weight_momentums=np.zeros_like(layer.weights)\n",
    "                layer.bias_momentums=np.zeros_like(layer.biases)\n",
    "            weight_updates=self.momentum* layer.weight_momentums-self.current_learning_rate*layer.dweights\n",
    "            layer.weight_momentums=weight_updates\n",
    "        \n",
    "            bias_updates=self.momentum* layer.bias_momentums-self.current_learning_rate*layer.dbiases\n",
    "            layer.bias_momentums=bias_updates\n",
    "        \n",
    "        else:\n",
    "            weights_updates = -self.learning_rate * layer.dweights\n",
    "            biases_updates = -self.learning_rate * layer.dbiases\n",
    "        # This updates the weight and bias parameter\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates        \n",
    "            \n",
    "            \n",
    "    def post_update_params(self):\n",
    "        self.counter += 1\n",
    "\n",
    "\n",
    "#portion 2\n",
    "class Layer_Dense:\n",
    "    \n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        #the o.1 is because we want the weight to be less than 1\n",
    "        self.weights=0.1*np.random.randn(n_inputs,n_neurons)\n",
    "        #shaped this way so there is no need of transpose\n",
    "        #intializing biases are 0, were there is a biases for every neuron\n",
    "        self.biases=np.zeros((1,n_neurons))\n",
    "    def forward(self,inputs):\n",
    "        #forward pass, input data is multipled by weight and added to bias\n",
    "        self.output=np.dot(inputs,self.weights)+self.biases\n",
    "        self.inputs=inputs\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "        \n",
    "#Portion 3\n",
    "class Activation_Relu:\n",
    "    def forward(self,inputs):\n",
    "        self.output=np.maximum(0,inputs)\n",
    "        \n",
    "    def backward(self, dvalues):\n",
    "        # Copy of variables are made\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # when input values were negative, we get a gradient 0\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "#Portion 4\n",
    "class Activation_softmax():\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        exp_values=np.exp(inputs-np.max(inputs,axis=1,keepdims=True))\n",
    "        self.output=exp_values/np.sum(exp_values,axis=1, keepdims=True)\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "            # Create an array with the same shape as our derivatives\n",
    "            self.dinputs = np.empty_like(dvalues)\n",
    "            for i, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "                # reshape the output array to a singular column\n",
    "                single_output = single_output.reshape(-1, 1)\n",
    "                # Calculate Jacobian matrix of the output \n",
    "                jacobian = np.diagflat(single_output)-np.dot(single_output, single_output.T)\n",
    "                \n",
    "                self.dinputs[i] = np.dot(jacobian, single_dvalues)\n",
    "#portion 5\n",
    "class Categorical_Cross_Entropy_Loss:\n",
    "    def forward(self,y_true,y_predict):\n",
    "        #clipping data to prevent division by 0\n",
    "        y_predict_clipped=np.clip(y_predict,1e-7, 1-1e-7)\n",
    "        #label is sparse and not 1-hot\n",
    "        correct_confidences=y_predict_clipped[range(len(y_predict)),y_true]\n",
    "        losses=-np.log(correct_confidences)\n",
    "        loss=np.mean(losses)\n",
    "        #to get the input with the max confidence on each row\n",
    "        prediction=np.argmax(y_predict, axis=1)\n",
    "        #accuracy is the average no of time the predicted is equal true value\n",
    "        accuracy=np.mean(prediction==y_true)\n",
    "        return loss, accuracy\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        n_samples = len(dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # we convert labels to one-hot vector as they are sparse\n",
    "        #np.eye with index is used for this\n",
    "        y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # To ormalize gradient, we divide by no of samples\n",
    "        self.dinputs = self.dinputs / n_samples\n",
    "\n",
    "\n",
    "\n",
    "#no of neurons in output of layer1 is input of layer2\n",
    "layer1=Layer_Dense(n_inputs=28*28, n_neurons=128)\n",
    "activation1=Activation_Relu()\n",
    "\n",
    "layer2=Layer_Dense(n_inputs=128, n_neurons=128)\n",
    "activation2=Activation_Relu()\n",
    "\n",
    "layer3=Layer_Dense(n_inputs=128, n_neurons=128)\n",
    "activation3=Activation_Relu()\n",
    "\n",
    "layer4=Layer_Dense(n_inputs=128, n_neurons=128)\n",
    "activation4=Activation_Relu()\n",
    "\n",
    "layer5=Layer_Dense(n_inputs=128, n_neurons=10)\n",
    "activation5=Activation_Relu()\n",
    "\n",
    "softmax1=Activation_softmax()\n",
    "\n",
    "loss_function=Categorical_Cross_Entropy_Loss()\n",
    "\n",
    "optimizer=Optimizer_StoGradDesc()\n",
    "losses,accuracies=[],[]\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "    layer1.forward(X_train)\n",
    "    activation1.forward(inputs=layer1.output)\n",
    "\n",
    "    layer2.forward(activation1.output)\n",
    "    activation2.forward(inputs=layer2.output)\n",
    "\n",
    "    layer3.forward(activation2.output)\n",
    "    activation3.forward(inputs=layer3.output)\n",
    "\n",
    "    layer4.forward(activation3.output)\n",
    "    activation4.forward(inputs=layer4.output)\n",
    "\n",
    "    layer5.forward(activation4.output)\n",
    "    activation5.forward(inputs=layer5.output)\n",
    "\n",
    "\n",
    "    softmax1.forward(inputs=activation5.output)\n",
    "    #print(softmax1.output)\n",
    "    loss,accuracy=loss_function.forward(y_predict=softmax1.output,y_true=y_train)\n",
    "\n",
    "    \n",
    "    print('Epoch: ', epoch,'loss ', loss,'accuracy ', accuracy, 'lr')\n",
    "    losses.append(loss)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    #Back propagation \n",
    "\n",
    "    #the output of softmax is the input of loss#\n",
    "    #back_softmax=Activation_softmax()\n",
    "    #back_softmax.output=softmax1.output\n",
    "\n",
    "    #back_loss_function=Categorical_Cross_Entropy_Loss()\n",
    "    loss_function.backward(dvalues=softmax1.output ,y_true=y_train)\n",
    "\n",
    "    softmax1.backward(loss_function.dinputs)\n",
    "\n",
    "    layer5.backward(dvalues=softmax1.dinputs)\n",
    "    layer4.backward(dvalues=layer5.dinputs)\n",
    "    layer3.backward(dvalues=layer4.dinputs)\n",
    "    layer2.backward(dvalues=layer3.dinputs)\n",
    "    layer1.backward(dvalues=layer2.dinputs)\n",
    "\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(layer1)\n",
    "    optimizer.update_params(layer2)\n",
    "    optimizer.update_params(layer3)\n",
    "    optimizer.update_params(layer4)\n",
    "    optimizer.update_params(layer5)\n",
    "    optimizer.post_update_params()\n",
    "\n",
    "\n",
    "# plt.plot(losses)\n",
    "\n",
    "plt.plot(accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
